{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import libraries for listing countries\n",
    "#import pycountry\n",
    "#import pycountry_convert as pc\n",
    "\n",
    "# Import aux libraries\n",
    "from collections import Counter\n",
    "import re\n",
    "#from wordcloud import WordCloud\n",
    "\n",
    "# Import libraries for Spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher \n",
    "\n",
    "# Load model for Spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA on torch\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly installed\n",
    "print(torch.cuda.current_device())  # Returns the index of the current CUDA device\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transformers and others\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import own libraries\n",
    "from extract_info import extract_abstracts_bib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport extract_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export information from bib files to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the excel file with the abstracts information\n",
    "bib_directory   = '00_bibFiles'\n",
    "bib_file        = 'search_001'\n",
    "path_export     = extract_abstracts_bib(bib_file, bib_directory,'out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the extracted information, create a dataframe\n",
    "bib_file        = 'search_001'\n",
    "path_export_file = os.path.join('out', bib_file+'_export.xlsx')\n",
    "df_base = pd.read_excel(path_export_file)\n",
    "print(df_base.columns)\n",
    "print(df_base['abstract'][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and tokenize text using spacy\n",
    "def preprocess_text(doc):\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Tokenize abstracts and titles and add column filtering out the stopwords\n",
    "df_base['tokens_abstract']   = df_base['abstract'].apply(nlp)\n",
    "df_base['tokens_title']      = df_base['title'].apply(nlp)\n",
    "\n",
    "# Tokenize abstracts and titles and add column filtering out the stopwoordss\n",
    "df_base['f_tokens_abstract'] = df_base['tokens_abstract'].apply(preprocess_text)\n",
    "df_base['f_tokens_title']    = df_base['tokens_title'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the principal keywords of the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TokenClassificationPipeline,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "\n",
    "# Define keyphrase extraction pipeline\n",
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, all_outputs):\n",
    "        results = super().postprocess(\n",
    "            all_outputs=all_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])\n",
    "\n",
    "# Load pipeline\n",
    "model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"\n",
    "#model_name = 'ml6team/keyphrase-generation-keybart-inspec'\n",
    "extractor = KeyphraseExtractionPipeline(model=model_name, device=0)\n",
    "\n",
    "# Fastest\n",
    "model_2 = 'ml6team/keyphrase-extraction-distilbert-inspec'\n",
    "extractor_2 = KeyphraseExtractionPipeline(model=model_2, device=0)\n",
    "\n",
    "\n",
    "#exmaple = extractor(df_base['abstract'][1])\n",
    "#print (exmaple)\n",
    "example2 = extractor_2(df_base['abstract'][29])\n",
    "\n",
    "print(example2)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(extractor(df_base['abstract'][i]))\n",
    "\n",
    "#df_base['keywords']= df_base['abstract'].apply(lambda x: extractor(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\", device=0)\n",
    "for i in range(0, 20):\n",
    "    text = df_base['abstract'][i]\n",
    "    print(summarizer(text, max_length=100, min_length=30, do_sample=False))\n",
    "#text = df_base['abstract']\n",
    "#print(text)\n",
    "#print(summarizer(text, max_length=100, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 259\n",
    "title = df_base['title'][item]\n",
    "abstract = df_base['abstract'][item]\n",
    "doc = nlp(abstract)\n",
    "sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "title_embedding = model.encode(title)\n",
    "\n",
    "abstract_embeddings = np.mean(sentence_embeddings, axis=0)\n",
    "\n",
    "\n",
    "# cosine similarity\n",
    "abstract_scores = util.pytorch_cos_sim(sentence_embeddings, abstract_embeddings)\n",
    "title_score = util.pytorch_cos_sim(sentence_embeddings, title_embedding)\n",
    "\n",
    "doc_scores = abstract_scores.flatten()\n",
    "tit_scores = title_score.flatten()\n",
    "\n",
    "title_weight = 0.3\n",
    "combined_scores = (1-title_weight)*doc_scores+tit_scores*title_weight\n",
    "\n",
    "for i, score in enumerate(combined_scores):\n",
    "    print(f\"Sentence {i+1} Score: {score:.4f}\")\n",
    "    print(sentences[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to an excel file\n",
    "path_export_file = os.path.join('out', bib_file+'_export_tockens.xlsx')\n",
    "df_base.to_excel(path_export_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create entities\n",
    "df_base['entities_abstract'] = df_base['tokens_abstract'].apply(lambda x: [(ent.text, ent.label_) for ent in x.ents])\n",
    "\n",
    "# Create chunks\n",
    "df_base['chunks_abstract'] = df_base['tokens_abstract'].apply(lambda x: [(chunk.text, chunk.root.text) for chunk in x.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with most common entities types\n",
    "entities_list = [label for sublist in df_base['entities_abstract'] for ent, label in sublist]\n",
    "entities_counter = Counter(entities_list)\n",
    "df_entities = pd.DataFrame(entities_counter.items(), columns=['label', 'count'])\n",
    "df_entities = df_entities.sort_values(by='count', ascending=False)\n",
    "df_entities['label_desc'] = df_entities['label'].apply(lambda x: spacy.explain(x) if spacy.explain(x) else x)\n",
    "df_entities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the common tokens of titles and abstracts\n",
    "tokens_counter = Counter([word for sublist in df_base['f_tokens_abstract'] for word in sublist])\n",
    "common_words = tokens_counter.most_common(15)\n",
    "\n",
    "ents_counter = Counter([ent for sublist in df_base['entities_abstract'] for ent, label in sublist])\n",
    "common_ents = ents_counter.most_common(15)\n",
    "\n",
    "# Create a hbar plot of the most common filtered words\n",
    "fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "unfiltered_plt = ax1.barh(*zip(*common_words))\n",
    "ax1.set_ylabel('Word')\n",
    "ax1.set_title('Most common words')\n",
    "ax1.bar_label(unfiltered_plt)\n",
    "\n",
    "filtered_plt = ax2.barh(*zip(*common_ents))\n",
    "ax2.set_ylabel('Entity')\n",
    "ax2.set_title('Common entities')\n",
    "ax2.bar_label(filtered_plt)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data PRISMA information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Title\n",
    "- Identify from the title if the article a systematic review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check from the tokens titles if any is 'review'\n",
    "df_base['PRISMA_1_is_review'] = df_base['f_tokens_title'].apply(lambda x: 'review' in x)\n",
    "df_filtered = df_base[df_base['PRISMA_1_is_review'] == True]\n",
    "for index, row in df_filtered.iterrows():\n",
    "    print(row['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the results to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the save information, create a dataframe\n",
    "bib_file        = 'search_001'\n",
    "path_export_file = os.path.join('out', bib_file+'_export_tockens.xlsx')\n",
    "df_base = pd.read_excel(path_export_file)\n",
    "print(df_base.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Objectives\n",
    "- Provide an explicit statement of the main objective(s) or question(s) the review addresses\n",
    "- Extract if exists a objective from the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sentences from a single document\n",
    "def extract_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisys with Q/A to find objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify main sentences by applying the function to the abstracts\n",
    "\n",
    "model_similarity = SentenceTransformer(\"all-MiniLM-L6-v2\", similarity_fn_name=SimilarityFunction.COSINE, device=0)\n",
    "\n",
    "def similarity_matrix(title, abstract):\n",
    "    # Find the similarity between the title and the abstract\n",
    "    title_embedding     = model_similarity.encode(title)\n",
    "\n",
    "    sentences           = extract_sentences(abstract)\n",
    "    sentence_embeddings = model_similarity.encode(sentences)\n",
    "\n",
    "    abstract_embeddings = np.mean(sentence_embeddings, axis=0)\n",
    "\n",
    "    # Calculate the cosine similarity between the title and the abstract\n",
    "    abstract_scores     = util.pytorch_cos_sim(sentence_embeddings, abstract_embeddings)\n",
    "    title_score         = util.pytorch_cos_sim(sentence_embeddings, title_embedding)\n",
    "\n",
    "    # Combine the scores\n",
    "    doc_scores = abstract_scores.flatten()\n",
    "    tit_scores = title_score.flatten()\n",
    "    \n",
    "    title_weight    = 0.3\n",
    "    combined_scores = (1-title_weight)*doc_scores + tit_scores*title_weight\n",
    "    \n",
    "    # Return the sentence with the highest similarity\n",
    "    return combined_scores\n",
    "\n",
    "# Check if it is working\n",
    "df_report = df_base[['title', 'abstract']].copy()\n",
    "df_report['sentences_weights'] = df_report.apply(lambda x: similarity_matrix(x['title'], x['abstract']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report['sentences'] = df_report['abstract'].apply(extract_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the verbs for each sentence\n",
    "def look_for_verbs_dobj(abstract):\n",
    "    sentences = extract_sentences(abstract)\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        verb_list = []\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "                if token.head.dep_ != 'advcl':\n",
    "            #if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "            #    if token.head.dep_ == 'ROOT':\n",
    "                    #value = token.head.lemma_+token.text.upper()\n",
    "                    verb_list.append(token.head.lemma_+token.text.capitalize())\n",
    "        result.append(verb_list)\n",
    "    return result\n",
    "            \n",
    "df_report['verbs_objective'] = df_report['abstract'].apply(look_for_verbs_dobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with a list of verbs from verbs_objective\n",
    "list_verbs = df_report['top_ROOT_verb'].explode().dropna()\n",
    "list_verbs = list_verbs.explode().dropna().str.lower()\n",
    "print(list_verbs)\n",
    "# split at mayus characters\n",
    "#list_verbs = list_verbs.str.split(r'[A-Z][^A-Z]*').explode().dropna()\n",
    "#list_verbs = [verb for sublist in list_verbs for verb in sublist]\n",
    "# Count the verbs\n",
    "verbs_counter = Counter(list_verbs)\n",
    "# Create a df with the verbs\n",
    "df_verbs = pd.DataFrame(verbs_counter.items(), columns=['verb', 'count'])\n",
    "df_verbs = df_verbs.sort_values(by='count', ascending=False)\n",
    "df_verbs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with a list of verbs from verbs_objective\n",
    "list_subj = df_report['subjects'].explode().dropna()\n",
    "list_subj = [subj for sublist in list_subj for subj in sublist]\n",
    "# Count the verbs\n",
    "subj_counter = Counter(list_subj)\n",
    "# Create a df with the verbs\n",
    "df_subj = pd.DataFrame(subj_counter.items(), columns=['subj', 'count'])\n",
    "df_subj = df_subj.sort_values(by='count', ascending=False)\n",
    "df_subj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the verbs for each sentence\n",
    "def look_for_verbs_dobj(sentences):\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        verb_list = []\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "                if token.head.dep_ != 'advcl':\n",
    "            #if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "            #    if token.head.dep_ == 'ROOT':\n",
    "                    #value = token.head.lemma_+token.text.upper()\n",
    "                    verb_list.append(token.head.lemma_+token.lemma_.capitalize())\n",
    "        result.append(verb_list)\n",
    "    return result\n",
    "\n",
    "# Extract the verbs for each sentence\n",
    "def look_for_verbs_ROOT(sentences):\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        verb_list = []\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'ROOT':\n",
    "                subj = [child.lemma_ for child in token.children if child.dep_ == 'nsubj']\n",
    "                verb_list.append(token.lemma_)\n",
    "        result.append(verb_list)\n",
    "    return result\n",
    "\n",
    "# Extract the subjects for each sentence\n",
    "def look_for_subjects(sentences):\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        subj_list = []\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'ROOT':\n",
    "                subj = [child.lemma_ for child in token.children if child.dep_ == 'nsubj']\n",
    "                if subj:\n",
    "                    subj_list.append(subj[0])\n",
    "        result.append(subj_list)\n",
    "    return result\n",
    "\n",
    "# Function to extract phrases based on semantic roles\n",
    "def extract_phrase2(sentences):\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        phrase_list = []\n",
    "        for token in doc:\n",
    "            # Check for phrases like \"in this review\" based on dependency tags and part-of-speech tags\n",
    "            if token.dep_ in ('prep') and token.head.dep_ == 'ROOT':\n",
    "                start = token.i\n",
    "                end = [child.i for child in token.children if child.dep_ == 'pobj']\n",
    "                if end:\n",
    "                    end = end[0]\n",
    "                    phrase_list.append( ' '.join([t.text.lower() for t in doc[start:end+1]]))\n",
    "        result.append(phrase_list)\n",
    "    return result\n",
    "\n",
    "#df_report['verbs_objective']    = df_report['sentences'].apply(look_for_verbs_dobj)\n",
    "#df_report['verbs_ROOT']    = df_report['sentences'].apply(look_for_verbs_ROOT)\n",
    "df_report['phrase_ROOT']   = df_report['sentences'].apply(extract_phrase2)\n",
    "#df_report['subjects']           = df_report['sentences'].apply(look_for_subjects)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained QA model and tokenizer\n",
    "qa_pipeline = pipeline('question-answering', model=\"distilbert-base-uncased-distilled-squad\", device=0)\n",
    "\n",
    "# Function to find the objective of the paper\n",
    "def objective_weights_qa(paragraph, question):\n",
    "    result = qa_pipeline(question=question, context=paragraph)\n",
    "    \n",
    "    doc = nlp(paragraph)\n",
    "    # Find whole sentence where the answer is\n",
    "    for sent in doc.sents:\n",
    "        if sent.start_char <= result['start'] and sent.end_char >= result['end']:\n",
    "            sentence = sent.text\n",
    "            break        \n",
    "        else:\n",
    "            sentence = 'Not found'\n",
    "        \n",
    "    return sentence\n",
    "\n",
    "# Define the questions\n",
    "queries = [\n",
    "    \"What is the objective of this paper/work/study?\",\n",
    "    \"What does the paper/work/study analyze?\",\n",
    "    \"What question is addressed in the paper/work/study?\",\n",
    "    \"What research question does this study aim to answer?\",\n",
    "    \"What is the main purpose of the paper/work/study?\",\n",
    "    \"What this paper/work/study investigate?\"\n",
    "    \"What does this study seek to accomplish?\"   \n",
    "    ]\n",
    "\n",
    "# Apply the function to the abstracts\n",
    "def matrix_QA_objective(abstract, sentences, queries):\n",
    "    results = []\n",
    "    for query in queries:\n",
    "        sentence_result = objective_weights_qa(abstract, query)\n",
    "        results.append(sentence_result)\n",
    "    \n",
    "    count_results = Counter(results)\n",
    "    count_matrix = np.zeros(len(sentences))\n",
    "    for i, sent in enumerate(sentences):\n",
    "        count_matrix[i] = count_results[sent]\n",
    "    \n",
    "    count_matrix = count_matrix/np.sum(count_matrix) if np.sum(count_matrix) != 0 else count_matrix\n",
    "    return count_matrix\n",
    "\n",
    "# Check if it is working\n",
    "##item = 0\n",
    "##abstract = df_report['abstract'][item]\n",
    "##sentences = df_report['sentences'][item]\n",
    "##\n",
    "##print(matrix_QA_objective(abstract, sentences, queries))\n",
    "\n",
    "# Apply function to the dataframe\n",
    "df_report['objective_QA_weights'] = df_report.apply(lambda x: matrix_QA_objective(x['abstract'], x['sentences'], queries), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix with boolean indexes if the subject is on the list\n",
    "def new_weight(verbs, subjects, IN_phrase_root, QA_weights, weights):\n",
    "    exclude_conlusion_verbs     = ['show', 'reveal', 'indicate', 'confirm', 'demonstrate', 'provide', 'find', 'showcase', 'highlight', 'suggest', 'achieve',\n",
    "                                   'account', 'contribute', \n",
    "                                   ]\n",
    "    include_subjects            = ['study', 'paper', 'work', 'research', ]\n",
    "    include_IN_phrase_root      = ['in this study', 'in the current study', 'through this study', 'in the present study',\n",
    "                                   'in this paper',\n",
    "                                   'in this work', 'in the present work', 'through this work',\n",
    "                                   'in this article', ]\n",
    "\n",
    "    w_exclude = []\n",
    "    w_inc_subj = []\n",
    "    w_inc_IN = []\n",
    "\n",
    "    for verb in verbs:\n",
    "        _exclude = any([token in exclude_conlusion_verbs for token in verb])\n",
    "        w_exclude.append(int(_exclude))\n",
    "\n",
    "    for subj in subjects:\n",
    "        _include = any([token in include_subjects for token in subj])\n",
    "        w_inc_subj.append(int(_include))\n",
    "    \n",
    "    for IN_phrase in IN_phrase_root:\n",
    "        _include = any([token in include_IN_phrase_root for token in IN_phrase])\n",
    "        w_inc_IN.append(int(_include))\n",
    "\n",
    "    # Matrix to identify last sentence\n",
    "    last_sentence = np.zeros(len(verbs))\n",
    "    last_sentence[-1] = 1\n",
    "\n",
    "    w_exclude = np.array(w_exclude)\n",
    "    w_inc_subj = np.array(w_inc_subj)\n",
    "    w_inc_IN = np.array(w_inc_IN) \n",
    "    weights = weights.numpy()\n",
    "    w_sbj = np.logical_or(w_inc_subj, w_inc_IN).astype(int)\n",
    "\n",
    "    n_weights = weights*(1 + w_sbj*0.15)\n",
    "    n_weights = n_weights*(1 + QA_weights*0.3) \n",
    "    n_weights = n_weights * (1 - w_exclude)\n",
    "    n_weights = n_weights * (1 - last_sentence*0.2)\n",
    "    #return n_weights, w_exclude, w_inc_subj, w_inc_IN, w_sbj\n",
    "    return n_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if it is working\n",
    "item = 20\n",
    "weights = df_report['sentences_weights'][item]\n",
    "in_phrase_root = df_report['phrase_ROOT'][item]\n",
    "subjects = df_report['subjects'][item]\n",
    "verbs = df_report['verbs_ROOT'][item]\n",
    "QA_w = df_report['objective_QA_weights'][item]\n",
    "n_weights, w_exclude, w_inc_subj, w_inc_IN, w_sbj = new_weight(verbs, subjects,in_phrase_root, QA_w,weights)\n",
    "#\n",
    "#print(n_weights)\n",
    "\n",
    "print(weights)\n",
    "print(QA_w)\n",
    "print(w_sbj)\n",
    "print(n_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_report['n_weights'] = df_report.apply(lambda x: new_weight(x['verbs_ROOT'], x['subjects'], x['phrase_ROOT'], x['objective_QA_weights'], x['sentences_weights']), axis=1)\n",
    "df_report['top_nsentence'] = df_report.apply(lambda x: x['sentences'][np.argmax(x['n_weights'])], axis=1)\n",
    "df_report['top_verb'] = df_report.apply(lambda x: x['verbs_objective'][np.argmax(x['n_weights'])], axis=1)\n",
    "df_report['top_ROOT_verb'] = df_report.apply(lambda x: x['verbs_ROOT'][np.argmax(x['n_weights'])], axis=1)\n",
    "\n",
    "# Top Sentence with weights\n",
    "df_report_check = df_base[['title']].copy()\n",
    "\n",
    "# With sentence_weights\n",
    "df_report_check['top_sentence_w']   = df_report.apply(lambda x: x['sentences'][np.argmax(x['sentences_weights'])], axis=1)\n",
    "df_report_check['top_ROOT_w']       = df_report.apply(lambda x: x['verbs_ROOT'][np.argmax(x['sentences_weights'])], axis=1)\n",
    "\n",
    "# With objective_QA_weights\n",
    "df_report_check['top_sentence_QA']   = df_report.apply(lambda x: x['sentences'][np.argmax(x['objective_QA_weights'])], axis=1)\n",
    "df_report_check['top_ROOT_QA']       = df_report.apply(lambda x: x['verbs_ROOT'][np.argmax(x['objective_QA_weights'])], axis=1)\n",
    "\n",
    "# With n_weights\n",
    "df_report_check['top_sentence_n']   = df_report.apply(lambda x: x['sentences'][np.argmax(x['n_weights'])], axis=1)\n",
    "df_report_check['top_ROOT_n']       = df_report.apply(lambda x: x['verbs_ROOT'][np.argmax(x['n_weights'])], axis=1)\n",
    "\n",
    "# Check if top_nsentence is equal to top sentence\n",
    "df_report_check['is_equal'] = df_report_check['top_sentence_QA'] == df_report_check['top_sentence_w']\n",
    "df_report_check['is_last'] = df_report['n_weights'].apply(np.argmax)==df_report['n_weights'].apply(len)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the results to an excel file\n",
    "path_export_file = os.path.join('out', bib_file+'_export_tockens_part2.xlsx')\n",
    "df_report_check.to_excel(path_export_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_exp = 157\n",
    "abstract = df_report['abstract'][item_exp]\n",
    "w_exp = df_report['n_weights'][item_exp]\n",
    "verbs = df_report['verbs_ROOT'][item_exp]\n",
    "subjects = df_report['subjects'][item_exp]\n",
    "item = np.argmax(w_exp).item()\n",
    "\n",
    "print(item, verbs[item])\n",
    "for i, sentence in enumerate(extract_sentences(abstract)):\n",
    "    print(i, f'{w_exp[i]*100:,.1f}', verbs[i], subjects[i])\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrase2(sentences):\n",
    "    result = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        phrase_list = []\n",
    "        for token in doc:\n",
    "            # Check for phrases like \"in this review\" based on dependency tags and part-of-speech tags\n",
    "            if token.dep_ in ('prep') and token.head.dep_ == 'ROOT':\n",
    "                start = token.i\n",
    "                end = [child.i for child in token.children if child.dep_ == 'pobj']\n",
    "                if end:\n",
    "                    end = end[0]\n",
    "                    phrase_list.append( ' '.join([t.lemma_.lower() for t in doc[start:end+1]]))\n",
    "        result.append(phrase_list)\n",
    "    return result\n",
    "\n",
    "txt = ['For this production pathway, a high renewable energy potential, especially in solar energy, is crucial.']\n",
    "\n",
    "print(extract_phrase2(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'We conclude that H2 geo-storage in deep coal seams is feasible from a fundamental petro-physical perspective; this work thus aids in the large-scale implementation of a hydrogen economy.'\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # if token is verb\n",
    "    if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "        print(token.head.text, token.text)\n",
    "\n",
    "for token in doc:\n",
    "    # if token is verb\n",
    "    if token.dep_ == 'ROOT':\n",
    "        subj = [child.lemma_ for child in token.children if child.dep_ == 'nsubj']\n",
    "        print(token.lemma_, subj)\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained QA model and tokenizer\n",
    "qa_pipeline = pipeline('question-answering', model=\"distilbert-base-uncased-distilled-squad\", device=0)\n",
    "\n",
    "# Function to find the objective of the paper\n",
    "def objective_finder_qa(paragraph, question):\n",
    "    result = qa_pipeline(question=question, context=paragraph)\n",
    "    \n",
    "    doc = nlp(paragraph)\n",
    "    # Find whole sentence where the answer is\n",
    "    for sent in doc.sents:\n",
    "        if sent.start_char <= result['start'] and sent.end_char >= result['end']:\n",
    "            sentence = sent.text\n",
    "            break        \n",
    "        else:\n",
    "            sentence = 'Not found'\n",
    "        \n",
    "    return result['answer'], sentence\n",
    "\n",
    "# Define the question to be asked\n",
    "queries = [\n",
    "    \"What is the objective of this paper/work/study?\",\n",
    "    \"What does the paper/work/study analyze?\",\n",
    "    \"What question is addressed in the paper/work/study?\",\n",
    "    \"What research question does this study aim to answer?\",\n",
    "    \"What is the main purpose of the paper/work/study?\",\n",
    "    \"What this paper/work/study investigate?\"\n",
    "    \"What does this study seek to accomplish?\"   \n",
    "    ]\n",
    "\n",
    "for i in range(len(queries)):\n",
    "   df_base[f'QA_objective_{i+1}'] = df_base['abstract'].apply(objective_finder_qa, question=queries[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results\n",
    "df_base.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the save information, create a dataframe\n",
    "bib_file        = 'search_001'\n",
    "path_export_file = os.path.join('out', bib_file+'_export_tockens_part2.xlsx')\n",
    "df_report_check = pd.read_excel(path_export_file)\n",
    "print(df_report_check.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens to be used\n",
    "df_report_check['tokens_objective'] = df_report_check['top_sentence_n'].apply(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "#import umap\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", similarity_fn_name=SimilarityFunction.COSINE, device=0)\n",
    "\n",
    "df_report_check['for_clustering'] = df_report_check.apply(lambda x: '. '.join([x['title'], x['top_sentence_w']]), axis=1)\n",
    "#df_report_check['for_clustering'] = df_base['abstract']\n",
    "\n",
    "sentences = df_report_check['for_clustering']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#reduce the dimensionality of the embeddings\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15, n_components=1, metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "# perform clustering on the reduced embeddings\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "# extract the cluster labels\n",
    "df_report_check['cluster'] = cluster.labels_\n",
    "\n",
    "\n",
    "\n",
    "cluster_labels = cluster.labels_\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(umap_embeddings, cluster_labels)\n",
    "sample_silhouette_values = silhouette_samples(umap_embeddings, cluster_labels)\n",
    "\n",
    "# Plot silhouette scores\n",
    "def plot_silhouette(umap_embeddings, cluster_labels, sample_silhouette_values, silhouette_avg):\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 8)\n",
    "    \n",
    "    # The silhouette coefficient can range from -1, 1\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters\n",
    "    ax1.set_ylim([0, len(umap_embeddings) + (len(set(cluster_labels)) + 1) * 10])\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(len(set(cluster_labels))):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / len(set(cluster_labels)))\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    ax1.set_title(\"Silhouette plot for the various clusters\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks(np.arange(-0.1, 1.1, 0.2))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plot_silhouette(umap_embeddings, cluster_labels, sample_silhouette_values, silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tokens of the clusters\n",
    "tokens = df_report_check['tokens_objective']\n",
    "\n",
    "# Topic modeling\n",
    "from collections import defaultdict\n",
    "\n",
    "# group texts by cluster\n",
    "cluster_texts = defaultdict(list)\n",
    "for _tokens, label in zip(tokens, cluster_labels):\n",
    "    cluster_texts[label].append(_tokens)\n",
    "\n",
    "# Get the more representative tokens of each cluster\n",
    "def get_representative_tokens(tokens):\n",
    "    # Flatten the list of tokens\n",
    "    ents = [ent for sublist in tokens for ent in sublist]\n",
    "    # Count the tokens\n",
    "    token_counts = Counter(ents)\n",
    "    # Get the most common tokens\n",
    "    common_tokens = token_counts.most_common(10)\n",
    "    return common_tokens\n",
    "\n",
    "# Get the most representative tokens for each cluster\n",
    "cluster_representative_tokens = {\n",
    "    label: get_representative_tokens(tokens) for label, tokens in cluster_texts.items()\n",
    "}\n",
    "# Print the most representative tokens for each cluster\n",
    "for label, tokens in cluster_representative_tokens.items():\n",
    "    print(f\"Cluster {label}: {tokens}\")\n",
    "    print(\"----\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisys using the title similarity with the abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similarity between the title and the abstract\n",
    "\n",
    "model_similarity = SentenceTransformer(\"all-MiniLM-L6-v2\", similarity_fn_name=SimilarityFunction.COSINE)\n",
    "\n",
    "def similarity_title_abstract(title, abstract):\n",
    "    # Find the similarity between the title and the abstract\n",
    "    embeddings_title    = model_similarity.encode(title)\n",
    "    sentences           = extract_sentences(abstract)\n",
    "    embeddings_abstract = model_similarity.encode(sentences)\n",
    "\n",
    "    similarities        = util.pytorch_cos_sim(embeddings_title, embeddings_abstract)[0]\n",
    "\n",
    "    # Return the sentence with the highest similarity\n",
    "    max_sim_index = np.argmax(similarities)\n",
    "    return sentences[max_sim_index] , float(similarities[max_sim_index])\n",
    "    \n",
    "# Apply the function to the dataframe\n",
    "df_base['similarity_title_abstract'] = df_base.apply(lambda x: similarity_title_abstract(x['title'], x['abstract']), axis=1)\n",
    "\n",
    "# Check the results\n",
    "df_base['similarity_title_abstract'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the objective sentence is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sentences are the same\n",
    "df_report = df_base[['title', 'abstract']].copy()\n",
    "for i in range(len(queries)):\n",
    "    df_report[f'QA_objective_{i+1}'] = df_base[f'QA_objective_{i+1}'].apply(lambda x: x[1])\n",
    "\n",
    "df_report['QA_objective_0'] = df_base['similarity_title_abstract'].apply(lambda x: x[0])\n",
    "\n",
    "\n",
    "qa_columns = df_report.filter(like='QA_objective')\n",
    "# From the columns select the most repeated sentence\n",
    "df_report['objective'] = qa_columns.mode(axis=1)[0]\n",
    "\n",
    "# Check the how much the mode is repeated\n",
    "df_report['objective_count'] = qa_columns.apply(lambda x: x.value_counts().get(df_report.loc[x.name, 'objective'], 0), axis=1)\n",
    "\n",
    "# Tokenize the objective\n",
    "df_report['tokens_objective'] = df_report['objective'].apply(nlp)\n",
    "\n",
    "# Function to look for verbs and  dobj in the objective\n",
    "def look_for_verbs_dobj(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj':\n",
    "            value = token.head.lemma_+token.lemma_.capitalize()\n",
    "            return value\n",
    "df_report['verbs_objective'] = df_report['tokens_objective'].apply(look_for_verbs_dobj)\n",
    "\n",
    "# Export the results to an excel file\n",
    "df_report.to_excel('results_objective.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the results import the file\n",
    "report      = 'results_objective.xlsx'\n",
    "df_report   = pd.read_excel(report)\n",
    "print(df_report.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to look for verbs in the objective\n",
    "def look_for_verbs_dobj(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj' or token.dep_ == 'nsubjpass':\n",
    "            value = token.head.lemma_\n",
    "            return value\n",
    "df_report['verbs_objective'] = df_report['tokens_objective'].apply(look_for_verbs_dobj)\n",
    "\n",
    "# Function to look for verbs in the objective\n",
    "def look_for_verbs_ROOT(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            value = token.head.lemma_\n",
    "            return value\n",
    "df_report['verbs_ROOT'] = df_report['tokens_objective'].apply(look_for_verbs_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "# Apply function only if verb is not found\n",
    "txt = 'This paper aims to address this by developing a flexible techno-economic analysis (TEA) tool that can be used to evaluate the potential of future scenarios where hydrogen is produced, stored, and distributed within a region.'\n",
    "summ = summarizer(txt, max_length=20, min_length=0, do_sample=True)\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "\n",
    "# Load the SRL model from AllenNLP\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the sentence to be analyzed\n",
    "sentence = \"In this study, life cycle techno-economic and carbon footprint analysis is conducted to investigate the feasibility of the NH3 decomposition process in terms of economic performance and CO2 emissions.\"\n",
    "\n",
    "# Use the predictor to analyze the sentence\n",
    "result = predictor.predict(sentence=sentence)\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "def look_for_verbs_ROOT(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            value = token.head.lemma_\n",
    "            return value\n",
    "print(look_for_verbs_ROOT(sentence))\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
    "\n",
    "#\n",
    "#  Extract verbs and their arguments from the result\n",
    "verbs = result['verbs']\n",
    "\n",
    "# Function to parse the description and extract arguments\n",
    "def extract_arguments(description):\n",
    "    arguments = []\n",
    "    current_arg = \"\"\n",
    "    inside_arg = False\n",
    "    for char in description:\n",
    "        if char == \"[\":\n",
    "            inside_arg = True\n",
    "            current_arg = \"\"\n",
    "        elif char == \"]\":\n",
    "            inside_arg = False\n",
    "            if current_arg:\n",
    "                arguments.append(current_arg.strip())\n",
    "        elif inside_arg:\n",
    "            current_arg += char\n",
    "    return arguments\n",
    "\n",
    "# Extract and print the arguments for each verb\n",
    "for verb in verbs:\n",
    "    print(f\"Verb: {verb['verb']}\")\n",
    "    arguments = extract_arguments(verb['description'])\n",
    "    for arg in arguments:\n",
    "        print(arg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define your DataFrame\n",
    "data = {\n",
    "    'sentences': [\n",
    "        'In this study, life cycle techno-economic and carbon footprint analysis is conducted to investigate the feasibility of the NH3 decomposition process in terms of economic performance and CO2 emissions.',\n",
    "        'This research was carried out to investigate hydrogen demand and determine the optimum hydrogen delivery network employing truck transportation.',\n",
    "        'This study focuses on the development of a methodological framework for the design of a five-echelon hydrogen supply chain (HSC) (energy source, production, storage, transportation and fuelling station) considering the geographic level of implementation.'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "from transformers import (\n",
    "    TokenClassificationPipeline,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "\n",
    "# Define keyphrase extraction pipeline\n",
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, all_outputs):\n",
    "        results = super().postprocess(\n",
    "            all_outputs=all_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])\n",
    "\n",
    "# Load pipeline\n",
    "model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"\n",
    "extractor = KeyphraseExtractionPipeline(model=model_name)\n",
    "\n",
    "\n",
    "def extract_entities_and_relationships(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    entities = []\n",
    "    relations = []\n",
    "    \n",
    "    # Extract named entities\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    \n",
    "    # Extract relationships based on dependency parsing\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            # Find the subject and object for the verb\n",
    "            subject = [child.text for child in token.children if child.dep_ in ['nsubj', 'nsubjpass']]\n",
    "            obj = [child.text for child in token.children if child.dep_ in ['dobj', 'attr']]\n",
    "            relations.append({\n",
    "                'entity': subject,\n",
    "                'relation': token.text,\n",
    "                'context': obj\n",
    "            })\n",
    "    \n",
    "    return entities, relations\n",
    "\n",
    "# Apply extraction function to each sentence\n",
    "df[['entities', 'relations']] = df['sentences'].apply(lambda x: pd.Series(extract_entities_and_relationships(x)))\n",
    "#df['key'] = df['sentences'].apply(extractor)\n",
    "\n",
    "# Display the results\n",
    "print(df[['sentences', 'entities', 'relations']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define the sentence to be analyzed\n",
    "sentence = \"In this study, an HSC design that will minimize cost, carbon emission and security risk for Turkey is proposed.\"\n",
    "\n",
    "# Parse the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Render the dependency parse tree\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
    "\n",
    "# Extract verbs and their arguments\n",
    "verbs = [token for token in doc if token.pos_ == 'VERB']\n",
    "for verb in verbs:\n",
    "    print(f\"Verb: {verb.text}\")\n",
    "    print(\"Arguments:\")\n",
    "    for child in verb.children:\n",
    "        if child.dep_ in ['obj', 'nsubj', 'iobj', 'ccomp', 'xcomp']:\n",
    "            print(f\"  - {child.text} ({child.dep_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.interpret.saliency_interpreters import SimpleGradient\n",
    "from allennlp.predictors import Predictor\n",
    "\n",
    "inputs = {\"sentence\": \"a very well-made, funny and entertaining picture.\"}\n",
    "archive = (\n",
    "    \"https://storage.googleapis.com/allennlp-public-models/\"\n",
    "    \"basic_stanford_sentiment_treebank-2020.06.09.tar.gz\"\n",
    ")\n",
    "predictor = Predictor.from_path(archive)\n",
    "interpreter = SimpleGradient(predictor)\n",
    "interpretation = interpreter.saliency_interpret_from_json(inputs)\n",
    "\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_report[['abstract','objective', 'verbs_objective', 'summary', 'verbs_ROOT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core Arguments:\n",
    "\n",
    "    ARG0: The agent or doer of the action (typically the subject).\n",
    "    ARG1: The patient or receiver of the action (typically the direct object).\n",
    "    ARG2: The instrument, benefactive, or attribute (often used for indirect objects).\n",
    "    ARG3: The starting point, benefactive, or attribute (used for specific verbs).\n",
    "    ARG4: The ending point or result (used for specific verbs).\n",
    "\n",
    "Adjunct Arguments (Modifiers):\n",
    "\n",
    "    ARGM-TMP: Temporal, indicating when the action took place.\n",
    "    ARGM-LOC: Locative, indicating where the action took place.\n",
    "    ARGM-DIR: Directional, indicating the direction of the action.\n",
    "    ARGM-MNR: Manner, indicating how the action was performed.\n",
    "    ARGM-EXT: Extent, indicating how much of the action took place.\n",
    "    ARGM-PRP: Purpose, indicating why the action was performed.\n",
    "    ARGM-PNC: Purpose\n",
    "    ARGM-CAU: Cause, indicating the reason for the action.\n",
    "    ARGM-DIS: Discourse, indicating discourse markers (e.g., however, therefore).\n",
    "    ARGM-ADV: General adverbials not covered by other tags.\n",
    "    ARGM-MOD: Modal, indicating the modality of the action (e.g., can, might).\n",
    "    ARGM-NEG: Negation, indicating the negation of the action.\n",
    "    ARGM-COM: Comitative, indicating accompaniment (e.g., \"with\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models import pretrained\n",
    "from allennlp.predictors import Predictor\n",
    "\n",
    "# Load the SRL predictor\n",
    "predictor = pretrained.load_predictor(\"structured-prediction-srl\")\n",
    "\n",
    "# Define the sentence to be analyzed\n",
    "sentence = \"In the current study, strengths, weaknesses, opportunities, and threats (SWOT) analysis has been successfully applied to the clean hydrogen value chain in different sectors to determine Japans clean hydrogen value chains strengths, weaknesses, opportunities, and threats as a case study.\"\n",
    "\n",
    "# Use the predictor to analyze the sentence\n",
    "result = predictor.predict(sentence=sentence)\n",
    "\n",
    "# Display the result\n",
    "for verb in result['verbs']:\n",
    "    print(f\"Verb: {verb['verb']}\")\n",
    "    tags = verb['tags']\n",
    "    words = result['words']\n",
    "    arg_dict = {}\n",
    "    current_arg = None\n",
    "    for word, tag in zip(words, tags):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            current_arg = tag[2:]\n",
    "            arg_dict[current_arg] = [word]\n",
    "        elif tag.startswith(\"I-\") and current_arg:\n",
    "            arg_dict[current_arg].append(word)\n",
    "        else:\n",
    "            current_arg = None\n",
    "    for arg, words in arg_dict.items():\n",
    "        print(f\"{arg}: {' '.join(words)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "for token in nlp(sentence):\n",
    "    if token.dep_ == 'ROOT':\n",
    "        print(token.head.lemma_)\n",
    "\n",
    "displacy.render(nlp(sentence), style='dep', jupyter=True, options={'distance': 90})\n",
    "spacy.explain('acl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Create a pipeline for token classification\n",
    "nlp_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define the sentence to be analyzed\n",
    "sentence = \"In this study, life cycle techno-economic and carbon footprint analysis is conducted to investigate the feasibility of the NH3 decomposition process in terms of economic performance and CO2 emissions.\"\n",
    "\n",
    "# Tokenize and classify the sentence\n",
    "tokens = nlp_pipeline(sentence)\n",
    "\n",
    "# Display the tokens and their labels\n",
    "for token in tokens:\n",
    "    print(f\"Word: {token['word']}, Entity: {token['entity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'The minimization of the total hydrogen supply chain (HSC) network cost for Germany in 2030 and 2050 years is the objective of this study.'\n",
    "def look_for_verbs_dobj(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'dobj':\n",
    "            value = token.head.lemma_+token.lemma_.capitalize()\n",
    "            return value\n",
    "\n",
    "print(look_for_verbs_dobj(doc))\n",
    "\n",
    "doc = nlp(doc)\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
    "spacy.explain('nsubjpass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to determine the 'is_objective' value\n",
    "def determine_objective(obj1, obj2, obj3, con3, con4):\n",
    "\n",
    "    dictionary = ['review', 'paper', 'study', 'work']\n",
    "\n",
    "    def contains_keywords(obj, keywords):\n",
    "        for word in keywords:\n",
    "            if word in nlp(obj):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    if obj1==obj2 or obj1==obj3:\n",
    "        if obj1==con3 or obj1==con4:\n",
    "            return 'is conclusion'\n",
    "        else:\n",
    "            return '1 and (2 or 3) are the same'\n",
    "    elif obj2==obj3:\n",
    "        if obj2==con3 or obj2==con4:\n",
    "            return 'is conclusion'\n",
    "        else:\n",
    "            return '2 and 3 are the same'\n",
    "    else:\n",
    "        if contains_keywords(obj1, dictionary):\n",
    "            return 'key on obj1'\n",
    "        elif contains_keywords(obj2, dictionary):\n",
    "            return 'key on obj2'\n",
    "        elif contains_keywords(obj3, dictionary):\n",
    "            return 'key on obj3'\n",
    "        return None\n",
    "    \n",
    "# Apply the function to the dataframe\n",
    "df_report['is_objective'] = df_report.apply(lambda x: determine_objective(x['QA_objective_1'], x['QA_objective_2'], x['similarity_title_abstract'], x['QA_objective_3'], x['QA_objective_4']), axis=1)\n",
    "\n",
    "# Export the results to an excel file\n",
    "df_report.to_excel('results_objective.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load the model, here we use our base sized model\n",
    "model = CrossEncoder(\"mixedbread-ai/mxbai-rerank-large-v1\")\n",
    "\n",
    "df_base['sentences'] = df_base['abstract'].apply(extract_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
    "\n",
    "txt = \"Green ammonia production as an important application for propelling the upcoming hydrogen economy has not been paid much attention by China, the world's largest ammonia producer. As a result, related studies are limited. This paper explores potential supply chain design and planning strategies of green ammonia production in the next decade of China with a case study in Inner Mongolia. A hybrid optimization-based simulation approach is applied, considering traditional optimization approaches are insufficient to address uncertainties and dynamics in a long-term energy transition. Results show that the production cost of green ammonia will be at least twice that of the current level due to higher costs of hydrogen supply. Production accounts for the largest share of the total expense of green hydrogen (~80 %). The decline of electricity and electrolyser prices are key in driving down the overall costs. In addition, by-product oxygen is also considered in the model to assess its economic benefits. We found that by-product oxygen sales could partly reduce the total expense of green hydrogen (~12 % at a price of USD 85/t), but it also should be noted that the volatile price of oxygen may pose uncertainties and risks to the effectiveness of the offset. Since the case study may represent the favourable conditions in China due to the abundant renewable energy resources and large-scale ammonia industry in this region, we propose to take a moderate step towards green ammonia production, and policies should be focused on reducing the electricity price and capital investments in green hydrogen production. We assume the findings and implications are informative to planning future green ammonia production in China. \"\n",
    "sentences = txt.split('.')\n",
    "\n",
    "queries = [\n",
    "    'Exploring supply chain design and expansion planning of Chinas green ammonia production with an optimization-based simulation approach',\n",
    "]\n",
    "instruction = 'Represent this sentence for searching relevant passages: '\n",
    "\n",
    "query_embedding = model.encode([instruction+q for q in queries], normalize_embeddings=True)\n",
    "sentence_embeddings = model.encode(sentences, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "similarity = sentence_embeddings @ query_embedding.T\n",
    "print(similarity)\n",
    "print(sentences[np.argmax(similarity)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", similarity_fn_name=SimilarityFunction.DOT_PRODUCT)\n",
    "\n",
    "# Compute embeddings for the sentences\n",
    "\n",
    "expressions_objective = [\n",
    "    'This paper presents how to implement a sustainable transportation solution',\n",
    "    'This article proposes a coordinated planning model of power system generation and transmission',\n",
    "    'In this paper, we propose an optimal scheduling framework for trans-energy systems that evaluates the merits of the hydrogen supply chain',\n",
    "    'This study aims at developing the Hydrogen Economics and InfRAstructure optimization model',\n",
    "    'On this basis, an integrated HSC-EN model is elaborated upon to investigate the optimal investment and operation'\n",
    "]\n",
    "\n",
    "demo_sentence = df_base['sentences'][319]\n",
    "demo_title = df_base['title'][319]\n",
    "\n",
    "embeddings_sentence = model.encode(demo_sentence)\n",
    "embeddings_checks   = model.encode(expressions_objective)\n",
    "\n",
    "similarities = model.similarity(embeddings_sentence, embeddings_checks)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(similarities)\n",
    "\n",
    "# Initialize lists to store results\n",
    "average_similarities = []\n",
    "highest_similarity_sentences = []\n",
    "\n",
    "# Calculate similarities for each demo sentence\n",
    "for i, demo_embedding in enumerate(embeddings_sentence):\n",
    "    # Calculate similarity scores with all expressions_objective\n",
    "    similarities = np.dot(embeddings_checks, demo_embedding) / (\n",
    "        np.linalg.norm(embeddings_checks, axis=1) * np.linalg.norm(demo_embedding)\n",
    "    )\n",
    "    \n",
    "    # Get the average similarity\n",
    "    average_similarity = np.mean(similarities)\n",
    "    average_similarities.append(average_similarity)\n",
    "    \n",
    "    # Find the index of the highest similarity\n",
    "    highest_similarity_index = np.argmax(similarities)\n",
    "    highest_similarity_sentence = expressions_objective[highest_similarity_index]\n",
    "    highest_similarity_sentences.append(highest_similarity_sentence)\n",
    "\n",
    "    # Print results for each demo sentence\n",
    "    print(f\"Demo Sentence: {demo_sentence[i]}\")\n",
    "    print(f\"Average Similarity: {average_similarity}\")\n",
    "    print(f\"Highest Similarity Sentence: {highest_similarity_sentence}\")\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "sentences = df_base['abstract']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "import umap.umap_ as umap\n",
    "#reduce the dimensionality of the embeddings\n",
    "umap_embeddings = umap.UMAP(n_neighbors=2, n_components=5, metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "import hdbscan\n",
    "# perform clustering on the reduced embeddings\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "# extract the cluster labels\n",
    "df_base['cluster'] = cluster.labels_\n",
    "cluster_labels = df_base['cluster']\n",
    "#cluster_labels = cluster.labels_\n",
    "\n",
    "# Topic modeling\n",
    "from collections import defaultdict\n",
    "\n",
    "# group texts by cluster\n",
    "cluster_texts = defaultdict(list)\n",
    "for text, label in zip(sentences, cluster_labels):\n",
    "    cluster_texts[label].append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the clusters\n",
    "df_results = df_base[['title', 'abstract', 'cluster', 'objective']]\n",
    "df_results.to_excel('clusters.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the more representative tokens of each cluster\n",
    "def get_representative_tokens(texts):\n",
    "    #get the ents\n",
    "    #docs = nlp(\" \".join(texts))\n",
    "    ents = extractor(\" \".join(texts))\n",
    "    # Count the tokens\n",
    "    token_counts = Counter(ents)\n",
    "    # Get the most common tokens\n",
    "    common_tokens = token_counts.most_common(10)\n",
    "    return common_tokens\n",
    "\n",
    "# Get the most representative tokens for each cluster\n",
    "cluster_representative_tokens = {\n",
    "    label: get_representative_tokens(texts) for label, texts in cluster_texts.items()\n",
    "}\n",
    "# Print the most representative tokens for each cluster\n",
    "for label, tokens in cluster_representative_tokens.items():\n",
    "    print(f\"Cluster {label}: {tokens}\")\n",
    "    print(\"----\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in np.unique(cluster_labels):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    cluster_indices = np.where(cluster_labels == label)[0]\n",
    "    cluster_center = np.mean(umap_embeddings[cluster_indices], axis=0)\n",
    "    closest_index = cluster_indices[np.argmin(np.linalg.norm(umap_embeddings[cluster_indices] - cluster_center, axis=1))]\n",
    "    print(f\"Most representative text for cluster {label}: {sentences[closest_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sentences for cluster 0\n",
    "cluster_0_indices = np.where(cluster_labels == 1)[0]\n",
    "cluster_0_sentences = [sentences[i] for i in cluster_0_indices]\n",
    "print(cluster_0_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective_finder_rank(documents, question):\n",
    "    # Use the CrossEncoder to find the answer\n",
    "    try:\n",
    "        result = model.rank(question, documents, return_documents=True, top_k=1)\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing paragraph: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create column with the objective of the paper\n",
    "question = \"What is the objective of this paper/work/study?\"\n",
    "#df_base['objective_rank'] = df_base['sentences'].apply(objective_finder_rank, question=question)\n",
    "\n",
    "# Use parallel processing to speed up the computation\n",
    "#def process_row(row):\n",
    "#    return objective_finder_rank(row['sentences'], question)\n",
    "#\n",
    "#with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "#    df_base['objective_rank'] = list(executor.map(process_row, df_base.to_dict('records')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the results\n",
    "# extarct the score from the tuple\n",
    "df_base['objective_rank_score'] = df_base['objective_rank'].apply(lambda x: x[0]['score'])\n",
    "\n",
    "df_results = df_base[['title', 'abstract', 'objective_rank_score', 'objective_rank', 'objective']]\n",
    "df_results.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained model fine-tuned on a classification task\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\" # Example model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Initialize a pipeline for classification\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embeddings for the sentences\n",
    "embeddings_sentence = model.encode(sentences)\n",
    "embeddings_titles = model.encode(title_1)\n",
    "\n",
    "similarities = model.similarity(embeddings_sentence, embeddings_titles)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(similarities)\n",
    "\n",
    "# print sentence with highest similarity\n",
    "print(sentences[np.argmax(similarities)])\n",
    "print(title_1)\n",
    "print(paragraph_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the objective\n",
    "title_1 = df_base['title'][0]\n",
    "paragraph_1 = df_base['abstract'][0]\n",
    "\n",
    "\n",
    "# Function to extract sentences from a single document\n",
    "def extract_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences\n",
    "    return sentences\n",
    "\n",
    "# Extract sentences from the paragraph\n",
    "sentences = extract_sentences(paragraph_1)\n",
    "\n",
    "# Predict the sentiment\n",
    "print(title_1)\n",
    "for sentence in sentences:\n",
    "    # print sentence and the sentiment for eaach sentence\n",
    "    print(sentence)\n",
    "    print(classifier(sentence))\n",
    "\n",
    "# Predict the sentiment for the whole paragraph\n",
    "print(classifier(paragraph_1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the objective\n",
    "title_1 = df_base['title'][0]\n",
    "paragraph_1 = df_base['abstract'][0]\n",
    "\n",
    "\n",
    "# Function to extract sentences from a single document\n",
    "def extract_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences\n",
    "    return sentences\n",
    "\n",
    "# Extract sentences from the paragraph\n",
    "sentences = extract_sentences(paragraph_1)\n",
    "\n",
    "# Predict the sentiment\n",
    "print(title_1)\n",
    "for sentence in sentences:\n",
    "    # print sentence and the sentiment for eaach sentence\n",
    "    print(sentence)\n",
    "    print(classifier(sentence))\n",
    "\n",
    "# Predict the sentiment for the whole paragraph\n",
    "print(classifier(paragraph_1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the objective\n",
    "title_1 = df_base['title'][0]\n",
    "paragraph_1 = df_base['abstract'][0]\n",
    "\n",
    "\n",
    "# Function to extract sentences from a single document\n",
    "def extract_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences\n",
    "    return sentences\n",
    "\n",
    "# Extract sentences from the paragraph\n",
    "sentences = extract_sentences(paragraph_1)\n",
    "\n",
    "# Predict the sentiment\n",
    "print(title_1)\n",
    "for sentence in sentences:\n",
    "    # print sentence and the sentiment for eaach sentence\n",
    "    print(sentence)\n",
    "    print(classifier(sentence))\n",
    "\n",
    "# Predict the sentiment for the whole paragraph\n",
    "print(classifier(paragraph_1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the objective\n",
    "title_1 = df_base['title'][0]\n",
    "paragraph_1 = df_base['abstract'][0]\n",
    "\n",
    "\n",
    "# Function to extract sentences from a single document\n",
    "def extract_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences\n",
    "    return sentences\n",
    "\n",
    "# Extract sentences from the paragraph\n",
    "sentences = extract_sentences(paragraph_1)\n",
    "\n",
    "# Predict the sentiment\n",
    "print(title_1)\n",
    "for sentence in sentences:\n",
    "    # print sentence and the sentiment for eaach sentence\n",
    "    print(sentence)\n",
    "    print(classifier(sentence))\n",
    "\n",
    "# Predict the sentiment for the whole paragraph\n",
    "print(classifier(paragraph_1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, SimilarityFunction, util\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"What is the objective of this study?\"\n",
    "\n",
    "# Extract sentences from the paragraph\n",
    "sentences = extract_sentences(paragraph_1)\n",
    "\n",
    "# Compute the embeddings for the query and the sentences\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarities between the query and the sentences\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "\n",
    "# Rank sentences by similarity score\n",
    "ranks = [{'sentence': sentences[i], 'score': score.item()} for i, score in enumerate(cosine_scores)]\n",
    "\n",
    "# Select sentences with a score > 0.5 and sort by score\n",
    "ranks = [rank for rank in ranks if rank['score'] > 0.1]\n",
    "ranks = sorted(ranks, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Output the ranked sentences\n",
    "for rank in ranks:\n",
    "    print(f\"Sentence: {rank['sentence']}, Score: {rank['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained QA model and tokenizer\n",
    "qa_pipeline = pipeline('question-answering', model=\"distilbert-base-uncased-distilled-squad\", device=0)\n",
    "\n",
    "# Define the paragraph and the question\n",
    "n_index = 8\n",
    "title_1 = df_base['title'][n_index]\n",
    "paragraph = df_base['abstract'][n_index]\n",
    "question = \"What is the objective of this paper/work/study?\"\n",
    "\n",
    "# Use the QA pipeline to find the answer\n",
    "result = qa_pipeline(question=question, context=paragraph)\n",
    "\n",
    "# Print the extracted objective\n",
    "print('Title:', title_1)\n",
    "print(\"Objective:\", result['answer'])\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Analyze a paragraph\n",
    "#paragraph = \"The study aims to explore the impact of new regulations on small businesses.\"\n",
    "doc = nlp(paragraph)\n",
    "\n",
    "# Extract entities and potentially relevant verbs\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "actions = [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "print(\"Entities:\", entities)\n",
    "print(\"Actions:\", actions)\n",
    "\n",
    "# Based on entities and actions, infer the paragraph objective\n",
    "if \"study\" in actions or \"assess\" in actions:\n",
    "    print(\"Objective: Likely explaining a research goal or hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TokenClassificationPipeline,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "import numpy as np\n",
    "\n",
    "# Define keyphrase extraction pipeline\n",
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, all_outputs):\n",
    "        results = super().postprocess(\n",
    "            all_outputs=all_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])\n",
    "\n",
    "# Load pipeline\n",
    "model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"\n",
    "extractor = KeyphraseExtractionPipeline(model=model_name)\n",
    "\n",
    "text = df_base['abstract'][1]\n",
    "keyphrases = extractor(text)\n",
    "\n",
    "print(text)\n",
    "print(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "def merge_entities(entities):\n",
    "    if not entities:\n",
    "        return []\n",
    "    merged = []\n",
    "    current = entities[0]\n",
    "    for next_entity in entities[1:]:\n",
    "        if next_entity['label'] == current['label'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
    "            current['text'] = text[current['start']: next_entity['end']].strip()\n",
    "            current['end'] = next_entity['end']\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            current = next_entity\n",
    "    # Append the last entity\n",
    "    merged.append(current)\n",
    "    return merged\n",
    "\n",
    "\n",
    "model = GLiNER.from_pretrained(\"numind/NuNerZero\")\n",
    "\n",
    "# NuZero requires labels to be lower-cased!\n",
    "labels = [\"price\", \"chemical\", \"industry\"]\n",
    "labels = [l.lower() for l in labels]\n",
    "\n",
    "text = \"This paper investigates the techno-economic implications on air travel when fossil-based kerosene is phased out of the market, specifically focusing on the comparison between liquid hydrogen, liquid methane and renewable kerosene for ten exemplary flight routes to estimate the cost of air travel per passenger and 100 km distance travelled [Formula presented] for every fuel type. By considering the entire supply chain, including hydrogen production from renewable sources, synthesis, oversea transport, domestic distribution, and utilization, this study addresses the overarching question of whether it is more economical to change the fuel source or the fuel itself to reduce fossil kerosene usage in the aviation industry. It is demonstrated that aircraft acquisition costs play a minor role compared to fuel supply costs and specific fuel demand. The study shows that for electricity-based fuels, liquid hydrogen is the most economic option, even with a potential energy penalty, followed by liquid methane and renewable kerosene. The results for an aircraft with a capacity 180 passengers are 3.08, 4.57 and 5.11 [Formula presented] for liquid hydrogen, liquid methane and renewable kerosene, respectively. Challenges regarding storage and isolation requirements for cryogenic fuels in aviation are discussed, with assumptions made that these obstacles can be overcome to realize economic benefits. Additionally, the study suggests potential shifts in aircraft size selection by airlines to mitigate rising fuel prices in the future. The study advocates for the aviation industry's openness to new fuels like liquid hydrogen and liquid methane to alleviate the cost increase associated with phasing out fossil kerosene.\"\n",
    "    \n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "entities = merge_entities(entities)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"EmergentMethods/gliner_medium_news-v2.1\")\n",
    "labels = [\"person\", \"location\", \"date\", \"event\", \"facility\", \"vehicle\", \"price\", \"organization\", 'industry', 'chemical', 'country', 'storage', 'distribution']\n",
    "\n",
    "txt = 'Hydrogen liquefaction processes have effective function in the hydrogen supply chain. However low efficiency and high liquefaction costs are still the most important concerns about the liquefaction plants. In this study a new configuration for a hydrogen liquefier process is proposed and energy-exergy analyzed. The production rate of the liquid hydrogen (LH2) is 90 tons per day that can supply the required LH2 of at least 90 k-180 k hydrogen vehicles in an urban area that results in the reduction of pollutions caused by carbon dioxide emission. The process is simulated in Aspen HYSYS simulator. In addition, it is optimized thorough a trial and error approach that is a functional and simple method of complicated systems analysis. The process includes a mixed refrigerant (MR) refrigeration cycle that precools feed gas hydrogen from 25C temperature to 199.9C temperature. A new MR is used in a cascade Joule-Brayton cycle that deep-cools the low-temperature gaseous hydrogen from 199.9C temperature to 252.2C temperature in the cryogenic section of the plant. The novel process involves also an absorption refrigeration system (ARS) that cools some hydrogen streams in the precooling and cryogenic sections of the process. The consumed energy per kilogram of produced LH2 is achieved as 6.47kWh. This quantity is 2.89kWh in the ideal conditions. The exergy efficiency of the plant is evaluated to be 45.5% that is significantly more than the exergy efficiency of the in operating hydrogen liquefiers in the world. The energy analysis reveals that the coefficient of performance (COP) of the overall system is 0.2034. The achieved COP is a higher amount in compare to the other similar processes. A sensitivity analysis is done to show the effect of the various operation conditions of the process on the features of the plant. Accordingly, the optimum mass flow of the ARS is determined as 207kg/s for the proposed configuration. As well as, the effect of the change in the temperature approach of the heat exchangers and the changes in the adiabatic efficiency of the compressors and expanders on the SEC, COP, and the exergy efficiency of the overall plant is discussed. Furthermore, financial analysis of the plant estimates the capital expenditures (CAPEX), energy expenditures (EEX), and operational and maintenance expenditures (OMEX) as 25413 2000, 7370 2000, and 2033 2000 respectively. These can be specially improved be improving of the exergy efficiency of the plant. The results implicates that the proposed configuration has better performance indicators than the in-service liquefiers. Therefore, LHL plant manufacturer can be considered it in the design and development of new plants. As well as, researchers may utilize its operating conditions to improve the proposed processes. '\n",
    "entities = model.predict_entities(txt, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'what process this article has?',\n",
    "    'context': txt\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# c) Tokenize input\n",
    "inputs = tokenizer(QA_input[\"question\"], QA_input[\"context\"], return_tensors=\"pt\")\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# d) Show results\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "QA_input = {\n",
    "    'question': '?',\n",
    "    'context': txt\n",
    "}\n",
    "\n",
    "res = nlp(QA_input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "print(summarizer(txt, max_length=200, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
    "\n",
    "# Let's load the model and the tokenizer \n",
    "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name) # If you want to use the Tensorflow model \n",
    "                                                                    # just replace with TFPegasusForConditionalGeneration\n",
    "\n",
    "\n",
    "# Some text to summarize here\n",
    "text_to_summarize = \"Hydrogen liquefaction processes have effective function in the hydrogen supply chain. However low efficiency and high liquefaction costs are still the most important concerns about the liquefaction plants. In this study a new configuration for a hydrogen liquefier process is proposed and energy-exergy analyzed. The production rate of the liquid hydrogen (LH2) is 90 tons per day that can supply the required LH2 of at least 90 k-180 k hydrogen vehicles in an urban area that results in the reduction of pollutions caused by carbon dioxide emission. The process is simulated in Aspen HYSYS simulator. In addition, it is optimized thorough a trial and error approach that is a functional and simple method of complicated systems analysis. The process includes a mixed refrigerant (MR) refrigeration cycle that precools feed gas hydrogen from 25C temperature to 199.9C temperature. A new MR is used in a cascade Joule-Brayton cycle that deep-cools the low-temperature gaseous hydrogen from 199.9C temperature to 252.2C temperature in the cryogenic section of the plant. The novel process involves also an absorption refrigeration system (ARS) that cools some hydrogen streams in the precooling and cryogenic sections of the process. The consumed energy per kilogram of produced LH2 is achieved as 6.47kWh. This quantity is 2.89kWh in the ideal conditions. The exergy efficiency of the plant is evaluated to be 45.5% that is significantly more than the exergy efficiency of the in operating hydrogen liquefiers in the world. The energy analysis reveals that the coefficient of performance (COP) of the overall system is 0.2034. The achieved COP is a higher amount in compare to the other similar processes. A sensitivity analysis is done to show the effect of the various operation conditions of the process on the features of the plant. Accordingly, the optimum mass flow of the ARS is determined as 207kg/s for the proposed configuration. As well as, the effect of the change in the temperature approach of the heat exchangers and the changes in the adiabatic efficiency of the compressors and expanders on the SEC, COP, and the exergy efficiency of the overall plant is discussed. Furthermore, financial analysis of the plant estimates the capital expenditures (CAPEX), energy expenditures (EEX), and operational and maintenance expenditures (OMEX) as 25413 2000, 7370 2000, and 2033 2000 respectively. These can be specially improved be improving of the exergy efficiency of the plant. The results implicates that the proposed configuration has better performance indicators than the in-service liquefiers. Therefore, LHL plant manufacturer can be considered it in the design and development of new plants. As well as, researchers may utilize its operating conditions to improve the proposed processes. \"\n",
    "# Tokenize our text\n",
    "# If you want to run the code in Tensorflow, please remember to return the particular tensors as simply as using return_tensors = 'tf'\n",
    "input_ids = tokenizer(text_to_summarize, return_tensors=\"pt\").input_ids\n",
    "print(len(input_ids[0]))\n",
    "# Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=30, \n",
    "    num_beams=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Finally, we can print the generated summary\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Parallel processing\n",
    "# Use parallel processing to speed up the computation\n",
    "def process_row(row):\n",
    "    return objective_finder_qa(row['abstract'], question)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    df_base['objective'] = list(executor.map(process_row, df_base.to_dict('records')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  2242\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   21328 lr:  0.000000 avg.loss:  2.657776 ETA:   0h 0m 0s lr:  0.003114 avg.loss:  2.655280 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import tempfile\n",
    "\n",
    "# Convert list of abstracts to a single string, each abstract being a new line\n",
    "abstracts_str = \"\\n\".join(df_base['abstract'].tolist())\n",
    "\n",
    "# Create a temporary file to store the abstracts\n",
    "with tempfile.NamedTemporaryFile(mode='w+', delete=False) as tmp_file:\n",
    "    tmp_file.write(abstracts_str)\n",
    "    tmp_file_path = tmp_file.name\n",
    "\n",
    "# Train the FastText model\n",
    "model = fasttext.train_unsupervised(tmp_file_path, model='skipgram', minn=2, maxn=5, dim=300)  # or 'cbow'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check positive or negative feeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Dan-La/scientific-challenges-and-directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contrast = df_base[['title', 'abstract']].copy()\n",
    "df_contrast['sentences'] = df_contrast['abstract'].apply(extract_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "sentences = df_contrast['sentences'][2]\n",
    "classification = []\n",
    "for sentence in sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    grade = model.config.id2label[predicted_class_id]\n",
    "    classification.append(grade)\n",
    "\n",
    "df_results = pd.DataFrame({'sentence': sentences, 'classification': classification})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('challenge', '-'), ('-', '-'), ('challenge', '-'), ('-', '-'), ('-', '-'), ('-', '-'), ('challenge', 'direction'), ('challenge', '-')]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to clsasify the sentences as challenges or directions\n",
    "tokenizer_challenges    = AutoTokenizer.from_pretrained(\"DanL/scientific-challenges-and-directions\")\n",
    "model_challenges        = AutoModelForSequenceClassification.from_pretrained(\"DanL/scientific-challenges-and-directions\").to(device)\n",
    "\n",
    "def classify_challenge(sentences, model=model_challenges, tokenizer=tokenizer_challenges, threshold=0.8):\n",
    "    results = []\n",
    "    if sentences:  # Check if sentences list is not empty\n",
    "        encoding    = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs     = model(**encoding)\n",
    "        \n",
    "        logits      = outputs['logits'].sigmoid().cpu().detach().numpy()\n",
    "\n",
    "        # Apply thresholding to the logits\n",
    "        predicted_challenge = np.where(logits[:, 0] > threshold, 'challenge', '-')\n",
    "        predicted_direction = np.where(logits[:, 1] > threshold, 'direction', '-')\n",
    "\n",
    "        # Zip the results and append to the list\n",
    "        results = list(zip(predicted_challenge, predicted_direction))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to classify the sentences depending on their sentiment\n",
    "modelName_sentiment = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer_sentiment = DistilBertTokenizer.from_pretrained(modelName_sentiment)\n",
    "model_sentiment     = DistilBertForSequenceClassification.from_pretrained(modelName_sentiment).to(device)\n",
    "\n",
    "def classify_sentiment(sentences, model=model_sentiment, tokenizer=tokenizer_sentiment):\n",
    "    predicted_sentiment = []\n",
    "    if sentences:  # Check if sentences list is not empty\n",
    "        encoding    = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs     = model(**encoding)\n",
    "        \n",
    "        logits      = outputs['logits'].softmax(dim=1).cpu().detach().numpy()\n",
    "\n",
    "        # Get the predicted sentiment\n",
    "        predicted_sentiment = np.argmax(logits, axis=1)\n",
    "    \n",
    "    return predicted_sentiment\n",
    "\n",
    "sentences = df_contrast['sentences'][0]\n",
    "results = classify_challenge(sentences)\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "df_contrast['challennge'] = df_contrast['sentences'].apply(classify_challenge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the sentences that are classified as challenges\n",
    "df_check_sentences = df_contrast[['title', 'sentences', 'challennge']]\n",
    "df_exploded = df_check_sentences.explode(['challennge', 'sentences'])\n",
    "\n",
    "df_exploded[['challennge','direction']] = pd.DataFrame(df_exploded['challennge'].tolist(), index=df_exploded.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/killa1994/.conda/envs/envThesis/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clustering\n",
    "#import umap\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", similarity_fn_name=SimilarityFunction.COSINE, device=0)\n",
    "\n",
    "\n",
    "df_filter = df_exploded[ df_exploded['challennge']== 'challenge'].copy()\n",
    "sentences = df_filter['sentences'].to_list()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#reduce the dimensionality of the embeddings\n",
    "umap_embeddings = umap.UMAP(n_neighbors=25, n_components=10, metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "# perform clustering on the reduced embeddings\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "# extract the cluster labels\n",
    "df_filter['cluster'] = cluster.labels_\n",
    "\n",
    "\n",
    "\n",
    "cluster_labels = cluster.labels_\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(umap_embeddings, cluster_labels)\n",
    "sample_silhouette_values = silhouette_samples(umap_embeddings, cluster_labels)\n",
    "\n",
    "# Plot silhouette scores\n",
    "def plot_silhouette(umap_embeddings, cluster_labels, sample_silhouette_values, silhouette_avg):\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 8)\n",
    "    \n",
    "    # The silhouette coefficient can range from -1, 1\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters\n",
    "    ax1.set_ylim([0, len(umap_embeddings) + (len(set(cluster_labels)) + 1) * 10])\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(len(set(cluster_labels))):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / len(set(cluster_labels)))\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    ax1.set_title(\"Silhouette plot for the various clusters\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks(np.arange(-0.1, 1.1, 0.2))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plot_silhouette(umap_embeddings, cluster_labels, sample_silhouette_values, silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The aim of this paper is to evaluate the costs and GHG emissions of advanced biofuels production through hydrothermal liquefaction (HTL) of sewage sludge in The Netherlands targeting the marine fuels market.', 'The process evaluated consists of a distributed configuration of regional HTL plants co-located with wastewater treatment plants, with centralized hydrotreating co-located with an existing refinery at the Port of Rotterdam.', 'The process is simulated in ASPEN + based on published experimental data and the mass and energy balances are used as input for techno-economic and environmental evaluation.', 'Lifecycle GHG emissions of the HTL and hydrotreating processes are estimated using consequential modelling principles and background data from the Ecoinvent database and compared with the business-as-usual scenario of sludge mono-incineration and fossil marine fuels production.', 'The results indicate that the HTL + hydrotreating configuration has potential to deliver on-spec marine biofuels at a minimum fuel selling price between 410 and 1300 EUR/t, being at least 3 times more beneficial compared to the business-as-usual scenario from a GHG emissions perspective.', 'Future work is recommended to optimize the size and location of the HTL plants in order to decrease capital costs and to address uncertainties regarding the sludge gate fee and the costs associated with the aqueous and solid by-products treatment.', 'The results indicate the potential of such configuration in locations with relatively high population density and good transport infrastructure.', 'This can be the case of port areas around the North Sea with access to offshore renewable electricity for hydrogen production, where drop-in marine biofuels are expected to play a role with the increasing share of renewables in the marine fuels mix.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### inference function\n",
    "def inference(sentences, model=model, threshold=0.5):\n",
    "    results = []\n",
    "    if len(sentences): # sentences != NULL\n",
    "        encoding = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs['logits'].sigmoid().cpu().detach().numpy()\n",
    "        for logit, text in zip(logits, sentences):\n",
    "            results.append({'sequence':text, 'output': {'challenge': logit[0], 'direction': logit[1]}})\n",
    "    return results\n",
    "     \n",
    "\n",
    "### to play with the model insert your own sentences\n",
    "sentences = [\"we speculate that studying IL-6 will be beneficial.\",\n",
    "             \"severe atypical cases of pneumonia emerged and quickly spread worldwide.\",\n",
    "             \"in future studies, both PRRs should be tested as the cause for multiple deaths.\",\n",
    "             \"IbMADS1-transformed potatoes exhibited tuber morphogenesis in the fibrous roots.\",]\n",
    "\n",
    "results = inference(sentences, model=model)\n",
    "print(*results, sep='\\n')\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.4695394, 'index': 1, 'word': 'Hawk', 'start': 0, 'end': 4}, {'entity': 'I-MISC', 'score': 0.9075718, 'index': 2, 'word': '##ing', 'start': 4, 'end': 7}, {'entity': 'I-MISC', 'score': 0.95800185, 'index': 3, 'word': 'Ra', 'start': 8, 'end': 10}, {'entity': 'I-MISC', 'score': 0.43808076, 'index': 4, 'word': '##diation', 'start': 10, 'end': 17}, {'entity': 'I-PER', 'score': 0.99925953, 'index': 11, 'word': 'Stephen', 'start': 54, 'end': 61}, {'entity': 'I-PER', 'score': 0.9979808, 'index': 12, 'word': 'Hawk', 'start': 62, 'end': 66}, {'entity': 'I-PER', 'score': 0.9956766, 'index': 13, 'word': '##ing', 'start': 66, 'end': 69}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained model fine-tuned for NER\n",
    "model_name = 'dbmdz/bert-large-cased-finetuned-conll03-english'  # A model fine-tuned on CoNLL-03 for NER\n",
    "nlp_ner = pipeline(\"ner\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "# Perform NER\n",
    "text = \"Hawking Radiation is a theoretical prediction made by Stephen Hawking.\"\n",
    "ner_results = nlp_ner(text)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word  entity\n",
      "0             R   B-ORG\n",
      "1           ##E   I-ORG\n",
      "2       ##power   I-ORG\n",
      "3           ##E   I-ORG\n",
      "4           ##U   I-ORG\n",
      "5      European  B-MISC\n",
      "6        System  I-MISC\n",
      "7         Opera   I-ORG\n",
      "8        ##tors   I-ORG\n",
      "9       Belgium   B-LOC\n",
      "10  Netherlands   B-LOC\n",
      "11      Germany   B-LOC\n",
      "12           In  I-MISC\n",
      "13         ##te  I-MISC\n",
      "14        ##ger  I-MISC\n",
      "15         Line  I-MISC\n",
      "16         ##ar  I-MISC\n",
      "17  Programming  I-MISC\n",
      "18      Belgian  B-MISC\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"The REpowerEU plan prioritizes combining electrification with low-carbon hydrogen for a green energy shift. However, uncertainties surrounding the future hydrogen market and its supply costs impede the establishment of its value chain. Without definite plans for hydrogen production and infrastructure, investing in low-carbon hydrogen industrial processes is risky. Simultaneously, the absence of solid market interest poses challenges in deploying a hydrogen backbone. In recent years, European gas Transmission System Operators (TSOs) in Belgium, Netherlands, and Germany, have introduced various roadmaps for their prospective national hydrogen network. Despite the infrastructure proposals, detailed quantitative scenario analysis for the future hydrogen supply chain is still missing. This paper presents a hydrogen infrastructure model that employs Mixed Integer Linear Programming (MILP) for investment and operational cost optimization at detailed spatiotemporal resolution. A regionalization method is proposed to allocate the potential hydrogen consumption in different industrial sectors across various clusters within a country, represented as the prospective hydrogen demand nodes. The model assesses extreme supply scenarios to examine the robustness of the resulting network infrastructure and compare the system-levelized cost of hydrogen. A real-life case study focusing on the potential Belgian hydrogen supply chain showcases the model's capabilities and outputs. \"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "# Create table with word, entity\n",
    "entities = [(entity['word'], entity['entity']) for entity in ner_results]\n",
    "df_result = pd.DataFrame(entities, columns=['word', 'entity'])\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e671b1b948bd4c0e8c40434c76834faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/killa1994/.conda/envs/envThesis/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/home/killa1994/.conda/envs/envThesis/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/killa1994/.local/lib/python3.12/site-packages/gliner/model.py:489: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_file, map_location=torch.device(map_location))\n",
      "/home/killa1994/.local/lib/python3.12/site-packages/gliner/data_processing/processor.py:206: UserWarning: Sentence of length 355 has been truncated to 296\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word    entity\n",
      "0       Germany   country\n",
      "1       Germany   country\n",
      "2        Norway   country\n",
      "3         Spain   country\n",
      "4       Algeria   country\n",
      "5       Morocco   country\n",
      "6         Egypt   country\n",
      "7          2050      date\n",
      "8   Monte Carlo  software\n",
      "9        Norway   country\n",
      "10        Spain   country\n",
      "11      Algeria   country\n",
      "12      Morocco   country\n",
      "13      Germany   country\n",
      "14       Norway   country\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"EmergentMethods/gliner_medium_news-v2.1\", device=0)\n",
    "\n",
    "labels = ['person', \"location\", \"date\", \"event\", \"facility\", \"vehicle\", \"number\", \"organization\", 'country', 'software']\n",
    "\n",
    "entities = model.predict_entities(example, labels)\n",
    "\n",
    "entities = [(entity['text'], entity['label']) for entity in entities]\n",
    "df_result_2 = pd.DataFrame(entities, columns=['word', 'entity'])\n",
    "print(df_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/killa1994/.conda/envs/envThesis/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                word entity\n",
      "0                            Germany    LOC\n",
      "1         Levelized Cost of Hydrogen   MISC\n",
      "2                            Germany    LOC\n",
      "3                             Norway    LOC\n",
      "4                              Spain    LOC\n",
      "5                            Algeria    LOC\n",
      "6                            Morocco    LOC\n",
      "7                              Egypt    LOC\n",
      "8                           European   MISC\n",
      "9                        Monte Carlo   MISC\n",
      "10  Weighted Average Cost of Capital   MISC\n",
      "11                            Norway    LOC\n",
      "12                             Spain    LOC\n",
      "13        Levelized Cost of Hydrogen   MISC\n",
      "14                           Algeria    LOC\n",
      "15                           Morocco    LOC\n",
      "16                           Germany    LOC\n",
      "17                            Norway    LOC\n",
      "18                             Egypt    LOC\n",
      "19        Levelized Cost of Hydrogen   MISC\n",
      "20  Weighted Average Cost of Capital   MISC\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "example = \"The production of green hydrogen through electrolysis, utilizing renewable energies, is recognized as a pivotal element in the pursuit of decarbonization. In order to attain cost competitiveness for green hydrogen, reasonable generation costs are imperative. To identify cost-effective import partners for Germany, given its limited green hydrogen production capabilities, this study undertakes an exhaustive techno-economic analysis to determine the potential Levelized Cost of Hydrogen in Germany, Norway, Spain, Algeria, Morocco, and Egypt for the year 2050, which represents a critical milestone in European decarbonization efforts. Employing a stochastic approach with Monte Carlo simulations, the paper marks a significant contribution for projecting future cost ranges, acknowledging the multitude of uncertainties inherent in related cost parameters and emphasizing the importance of randomness in these assessments. Country-specific Weighted Average Cost of Capital are calculated in order to create a refined understanding of political and economic influences on cost formation, rather than using a uniform value across all investigated nations. Key findings reveal that among the evaluated nations, PV-based hydrogen emerges as the most cost-efficient alternative in all countries except Norway, with Spain presenting the lowest Levelized Cost of Hydrogen at 1.66 /kg to 3.12 /kg, followed by Algeria (1.72 /kg to 3.23 /kg) and Morocco (1.73 /kg to 3.28 /kg). Consequently, for economically favorable import options, Germany is advised to prioritize PV-based hydrogen imports from these countries. Additionally, hydrogen derived from onshore wind in Norway (2.24 /kg to 3.73 /kg) offers a feasible import alternative. To ensure supply chain diversity and reduce dependency on a single source, a mixed import strategy is advisable. Despite having the lowest electricity cost, Egypt shows the highest Levelized Cost of Hydrogen, primarily due to a significant Weighted Average Cost of Capital. \"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "entities = [(entity['word'], entity['entity_group']) for entity in ner_results]\n",
    "df_result_2 = pd.DataFrame(entities, columns=['word', 'entity'])\n",
    "print(df_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157a51c88cf24651aacd40f70071ae5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83da6c6e15704f9288a48c878c89cc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72779880b50b4536b116078d3e644149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a667bd33c6d146b1b063498582bfe285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604747757b294f6ba995d334ca8e8a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:30:08,894 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[331]: \"The production of green hydrogen through electrolysis, utilizing renewable energies, is recognized as a pivotal element in the pursuit of decarbonization. In order to attain cost competitiveness for green hydrogen, reasonable generation costs are imperative. To identify cost-effective import partners for Germany, given its limited green hydrogen production capabilities, this study undertakes an exhaustive techno-economic analysis to determine the potential Levelized Cost of Hydrogen in Germany, Norway, Spain, Algeria, Morocco, and Egypt for the year 2050, which represents a critical milestone in European decarbonization efforts. Employing a stochastic approach with Monte Carlo simulations, the paper marks a significant contribution for projecting future cost ranges, acknowledging the multitude of uncertainties inherent in related cost parameters and emphasizing the importance of randomness in these assessments. Country-specific Weighted Average Cost of Capital are calculated in order to create a refined understanding of political and economic influences on cost formation, rather than using a uniform value across all investigated nations. Key findings reveal that among the evaluated nations, PV-based hydrogen emerges as the most cost-efficient alternative in all countries except Norway, with Spain presenting the lowest Levelized Cost of Hydrogen at 1.66 /kg to 3.12 /kg, followed by Algeria (1.72 /kg to 3.23 /kg) and Morocco (1.73 /kg to 3.28 /kg). Consequently, for economically favorable import options, Germany is advised to prioritize PV-based hydrogen imports from these countries. Additionally, hydrogen derived from onshore wind in Norway (2.24 /kg to 3.73 /kg) offers a feasible import alternative. To ensure supply chain diversity and reduce dependency on a single source, a mixed import strategy is advisable. Despite having the lowest electricity cost, Egypt shows the highest Levelized Cost of Hydrogen, primarily due to a significant Weighted Average Cost of Capital.\"  [\"Germany\"/LOC, \"Germany\"/LOC, \"Norway\"/LOC, \"Spain\"/LOC, \"Algeria\"/LOC, \"Morocco\"/LOC, \"Egypt\"/LOC, \"European\"/MISC, \"Monte Carlo\"/LOC, \"Norway\"/LOC, \"Spain\"/LOC, \"Algeria\"/LOC, \"Morocco\"/LOC, \"Germany\"/LOC, \"Norway\"/LOC, \"Egypt\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence(example)\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('ner-large')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with all annotations\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:32:10,999 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-08 21:32:11,283 https://nlp.informatik.hu-berlin.de/resources/models/zelda/v2/zelda-v2.pt not found in cache, downloading to /tmp/tmpi9xv0tse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1.76G/1.76G [00:57<00:00, 32.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:33:09,101 copying /tmp/tmpi9xv0tse to cache at /home/killa1994/.flair/models/zelda-v2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:33:10,308 removing temp file /tmp/tmpi9xv0tse\n",
      "2024-08-08 21:33:19,210 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[24]: \"The production of green hydrogen through electrolysis, utilizing renewable energies, is recognized as a pivotal element in the pursuit of decarbonization.\"\n",
      "Sentence[16]: \"In order to attain cost competitiveness for green hydrogen, reasonable generation costs are imperative.\"\n",
      "Sentence[59]: \"To identify cost-effective import partners for Germany, given its limited green hydrogen production capabilities, this study undertakes an exhaustive techno-economic analysis to determine the potential Levelized Cost of Hydrogen in Germany, Norway, Spain, Algeria, Morocco, and Egypt for the year 2050, which represents a critical milestone in European decarbonization efforts.\"  [\"Germany\"/Germany, \"Germany\"/Germany, \"Norway\"/Norway, \"Spain\"/Spain, \"Algeria\"/Algeria, \"Morocco\"/Morocco, \"Egypt\"/Egypt, \"European\"/Europe]\n",
      "Sentence[41]: \"Employing a stochastic approach with Monte Carlo simulations, the paper marks a significant contribution for projecting future cost ranges, acknowledging the multitude of uncertainties inherent in related cost parameters and emphasizing the importance of randomness in these assessments.\"  [\"Monte Carlo\"/Monte_Carlo]\n",
      "Sentence[35]: \"Country-specific Weighted Average Cost of Capital are calculated in order to create a refined understanding of political and economic influences on cost formation, rather than using a uniform value across all investigated nations.\"\n",
      "Sentence[65]: \"Key findings reveal that among the evaluated nations, PV-based hydrogen emerges as the most cost-efficient alternative in all countries except Norway, with Spain presenting the lowest Levelized Cost of Hydrogen at 1.66 /kg to 3.12 /kg, followed by Algeria (1.72 /kg to 3.23 /kg) and Morocco (1.73 /kg to 3.28 /kg).\"  [\"PV-based\"/<unk>, \"Norway\"/Norway, \"Spain\"/Spain, \"Algeria\"/Algeria, \"Morocco\"/Morocco]\n",
      "Sentence[20]: \"Consequently, for economically favorable import options, Germany is advised to prioritize PV-based hydrogen imports from these countries.\"  [\"Germany\"/Germany, \"PV-based\"/<unk>]\n",
      "Sentence[24]: \"Additionally, hydrogen derived from onshore wind in Norway (2.24 /kg to 3.73 /kg) offers a feasible import alternative.\"  [\"Norway\"/Norway]\n",
      "Sentence[20]: \"To ensure supply chain diversity and reduce dependency on a single source, a mixed import strategy is advisable.\"\n",
      "Sentence[27]: \"Despite having the lowest electricity cost, Egypt shows the highest Levelized Cost of Hydrogen, primarily due to a significant Weighted Average Cost of Capital.\"  [\"Egypt\"/Egypt]\n",
      "Sentence[0]: \"\"\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "\n",
    "# initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "# use splitter to split text into list of sentences\n",
    "sentences = splitter.split(example)\n",
    "\n",
    "# predict tags for sentences\n",
    "tagger = Classifier.load('linker')\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# iterate through sentences and print predicted labels\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 22:03:32,707 SequenceTagger predicts: Dictionary with 47 tags: O, S-NP, B-NP, E-NP, I-NP, S-VP, B-VP, E-VP, I-VP, S-PP, B-PP, E-PP, I-PP, S-ADVP, B-ADVP, E-ADVP, I-ADVP, S-SBAR, B-SBAR, E-SBAR, I-SBAR, S-ADJP, B-ADJP, E-ADJP, I-ADJP, S-PRT, B-PRT, E-PRT, I-PRT, S-CONJP, B-CONJP, E-CONJP, I-CONJP, S-INTJ, B-INTJ, E-INTJ, I-INTJ, S-LST, B-LST, E-LST, I-LST, S-UCP, B-UCP, E-UCP, I-UCP, <START>, <STOP>\n",
      "Span[0:3]: \"This literature review\"  NP (0.9740)\n",
      "Span[3:4]: \"critically\"  ADVP (0.8480)\n",
      "Span[4:5]: \"examines\"  VP (0.5869)\n",
      "Span[5:10]: \"the current advantages and strategies\"  NP (0.9576)\n",
      "Span[10:11]: \"adopted\"  VP (0.9999)\n",
      "Span[11:12]: \"by\"  PP (0.9999)\n",
      "Span[12:14]: \"the GCC\"  NP (0.9996)\n",
      "Span[14:16]: \"to expedite\"  VP (0.9930)\n",
      "Span[16:18]: \"the implementation\"  NP (0.9989)\n",
      "Span[18:19]: \"of\"  PP (1.0000)\n",
      "Span[19:22]: \"hydrogen supply chains\"  NP (0.8397)\n",
      "Span[23:26]: \"as well as\"  CONJP (0.9895)\n",
      "Span[26:27]: \"investigation\"  NP (1.0000)\n",
      "Span[27:28]: \"into\"  PP (1.0000)\n",
      "Span[28:30]: \"the methodologies\"  NP (0.9950)\n",
      "Span[30:31]: \"employed\"  VP (0.9998)\n",
      "Span[31:32]: \"in\"  PP (0.9999)\n",
      "Span[32:34]: \"current research\"  NP (0.9962)\n",
      "Span[34:35]: \"for\"  PP (1.0000)\n",
      "Span[35:39]: \"the modelling and optimisation\"  NP (0.8731)\n",
      "Span[39:40]: \"of\"  PP (1.0000)\n",
      "Span[40:43]: \"hydrogen supply chains\"  NP (0.9067)\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load model\n",
    "tagger = SequenceTagger.load(\"flair/chunk-english-fast\")\n",
    "\n",
    "# make English sentence\n",
    "sentence = Sentence(\"This literature review critically examines the current advantages and strategies adopted by the GCC to expedite the implementation of hydrogen supply chains, as well as investigation into the methodologies employed in current research for the modelling and optimisation of hydrogen supply chains.\")\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the chunks\n",
    "for chunk in sentence.get_spans('np'):\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:57:12,713 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Span[13:14]: \"GCC\"  ORG (0.9928)\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# 1. make example sentence\n",
    "sentence = Sentence(\"This literature review critically examines the current advantages and strategies adopted by the GCC to expedite the implementation of hydrogen supply chains, as well as investigation into the methodologies employed in current research for the modelling and optimisation of hydrogen supply chains.\")\n",
    "\n",
    "# 2. load entity tagger and predict entities\n",
    "tagger = Classifier.load('ner-fast')\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# check which named entities have been found in the sentence\n",
    "entities = sentence.get_labels('ner')\n",
    "for entity in entities:\n",
    "    print(entity)\n",
    "\n",
    "# 3. load relation extractor\n",
    "extractor = Classifier.load('relations')\n",
    "\n",
    "# predict relations\n",
    "extractor.predict(sentence)\n",
    "\n",
    "# check which relations have been found\n",
    "relations = sentence.get_labels('relation')\n",
    "for relation in relations:\n",
    "    print(relation)\n",
    "\n",
    "# Use the `get_labels()` method with parameter 'relation' to iterate over all relation predictions. \n",
    "for label in sentence.get_labels('relation'):\n",
    "    print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
